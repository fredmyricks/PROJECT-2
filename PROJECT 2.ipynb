{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load airport, weather, and airline datasets\n",
    "airport_df = pd.read_csv('airports.csv')\n",
    "weather_df = pd.read_csv('weather.csv')\n",
    "airline_df = pd.read_csv('airlines.csv')\n",
    "\n",
    "# Display the first few rows of each dataset to understand their structures\n",
    "airport_df.head()\n",
    "weather_df.head()\n",
    "airline_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Analysis 1: Airport with the Highest Altitude\n",
    "highest_altitude_airport = airport_df.loc[airport_df['alt'].idxmax()]\n",
    "highest_altitude_airport\n",
    "\n",
    "\n",
    "# Analysis 2: Average Temperature per Year\n",
    "avg_temp_per_year = weather_df.groupby('year')['temp'].mean()\n",
    "avg_temp_per_year\n",
    "\n",
    "# Analysis 3: Number of Carriers\n",
    "num_carriers = airline_df['carrier'].nunique()\n",
    "num_carriers\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12db4c509d655b5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Tyding up the airports_data of the airports.cvs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'airports.csv' dataset\n",
    "airports_df = pd.read_csv('airports.csv')\n",
    "\n",
    "# Display the number of rows before cleaning\n",
    "print(f\"Number of rows before cleaning: {len(airports_df)}\")\n",
    "\n",
    "# Drop duplicates based on all columns\n",
    "airports_df_cleaned = airports_df.drop_duplicates()\n",
    "\n",
    "# Display the number of rows after cleaning\n",
    "print(f\"Number of rows after cleaning: {len(airports_df_cleaned)}\")\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "airports_df_cleaned.to_csv('cleaned_airports.csv', index=False)\n",
    "\n",
    "\n",
    "# Drop duplicates based on specific columns (e.g., 'faa' and 'name')\n",
    "airports_df_cleaned = airports_df.drop_duplicates(subset=['faa', 'name'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6007755677a8f078",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this cleanup:\n",
    "\n",
    "I loaded the 'airports.csv' dataset into a DataFrame using pd.read_csv.\n",
    "I printed the number of rows before cleaning.\n",
    "I use the drop_duplicates method to remove duplicate rows based on all columns.\n",
    "I printed the number of rows after cleaning.\n",
    "I saved the cleaned dataset to a new CSV file, 'cleaned_airports.csv'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab4e7d60eb08de2c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Tyding up the airlines_data of the airlines.cvs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'airlines.csv' dataset\n",
    "airlines_df = pd.read_csv('airlines.csv')\n",
    "\n",
    "# Display the number of rows before cleaning\n",
    "print(f\"Number of rows before cleaning: {len(airlines_df)}\")\n",
    "\n",
    "# Drop duplicates based on all columns\n",
    "airlines_df_cleaned = airlines_df.drop_duplicates()\n",
    "\n",
    "# Display the number of rows after cleaning\n",
    "print(f\"Number of rows after cleaning: {len(airlines_df_cleaned)}\")\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "airlines_df_cleaned.to_csv('cleaned_airlines.csv', index=False)\n",
    "\n",
    "# Drop duplicates based on specific columns (e.g., 'carrier' and 'name')\n",
    "airlines_df_cleaned = airlines_df.drop_duplicates(subset=['carrier', 'name'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16155c277315f3cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this cleanup:\n",
    "\n",
    "I loaded the 'airlines.csv' dataset into a DataFrame using pd.read_csv.\n",
    "I printed the number of rows before cleaning.\n",
    "I use the drop_duplicates method to remove duplicate rows based on all columns.\n",
    "I printed the number of rows after cleaning.\n",
    "I saved the cleaned dataset to a new CSV file, 'cleaned_airlines.csv'.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdda5d075ad453ab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 'weather.csv' dataset\n",
    "weather_df = pd.read_csv('weather.csv')\n",
    "\n",
    "# Display the number of rows and columns before cleaning\n",
    "print(f\"Number of rows before cleaning: {weather_df.shape[0]}\")\n",
    "print(f\"Number of columns before cleaning: {weather_df.shape[1]}\")\n",
    "\n",
    "# Drop duplicate rows based on all columns\n",
    "weather_df = weather_df.drop_duplicates()\n",
    "\n",
    "# Drop rows with missing values\n",
    "weather_df = weather_df.dropna()\n",
    "\n",
    "# Display the number of rows and columns after cleaning\n",
    "print(f\"Number of rows after cleaning: {weather_df.shape[0]}\")\n",
    "print(f\"Number of columns after cleaning: {weather_df.shape[1]}\")\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "weather_df.to_csv('cleaned_weather.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca193b7e6e7a60a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this cleanup:\n",
    "\n",
    "I loaded the 'weather.csv' dataset into a DataFrame using pd.read_csv.\n",
    "I printed the number of rows and columns before cleaning.\n",
    "I use the drop_duplicates method to remove duplicate rows based on all columns.\n",
    "I printed the number of rows and columns after cleaning.\n",
    "I saved the cleaned dataset to a new CSV file, 'cleaned_weather.csv'.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5409909027ae7533"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
